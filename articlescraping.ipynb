{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "url = 'https://dev.to/'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "    # Find the navigation links\n",
    "    nav_links = soup.find('ul', class_='default-navigation-links')\n",
    "\n",
    "    # Check if navigation links are found\n",
    "    if nav_links:\n",
    "        # Find all list items within the navigation links\n",
    "        list_items = nav_links.find_all('li')\n",
    "\n",
    "        # Search for the specific link with text \"/tags\"\n",
    "        tag_url = [item.a['href'] for item in list_items if item.a and item.a['href'] == '/tags']\n",
    "\n",
    "        # Combine the URL with the tags relative path\n",
    "        if tag_url:\n",
    "            full_tag_url = url + tag_url[0]\n",
    "            response = requests.get(full_tag_url)\n",
    "            soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "            # Find div links\n",
    "            div_links = soup.find_all('div', class_='js-tag-card')\n",
    "            if div_links:\n",
    "                anchor_tags = [div.find('a') for div in div_links if div.find('a')]\n",
    "\n",
    "                # Extract and print the href attributes of the anchor tags\n",
    "                anchor_hrefs = [tag['href'] for tag in anchor_tags if tag]\n",
    "\n",
    "                # Merge the URL with the hrefs extracted from their anchor tags\n",
    "                full_category_links = [url + href for href in anchor_hrefs]\n",
    "\n",
    "            for category in full_category_links:\n",
    "                response = requests.get(category)\n",
    "                soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "                # Phishing for links that get to the articles\n",
    "                article_div = soup.find_all('div', class_='crayons-story__indention')\n",
    "                if article_div:\n",
    "                    divs = [div.find('a') for div in article_div if div.find('a')]\n",
    "\n",
    "                    # Extract the hrefs in the anchor tags to achieve our purpose: extract articles\n",
    "                    article_href = [url + tag['href'] for tag in divs if tag]\n",
    "\n",
    "                    for article_link in article_href:\n",
    "                        response = requests.get(article_link)\n",
    "                        soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "                        # Scraping the articles now!!!\n",
    "                        article_body = soup.find_all('div', class_='crayons-article__main')\n",
    "\n",
    "                        # Assuming there's only one div with class 'crayons-article__main'\n",
    "                        if article_body:\n",
    "                            article_content = article_body[0].get_text()\n",
    "\n",
    "                            # Write the article content to a text file\n",
    "                            with open('articles.txt', 'a', encoding='utf-8') as file:\n",
    "                                file.write(article_content + '\\n' + '-' * 150 + '\\n')  # Add a line of dashes after each article\n",
    "\n",
    "                            # Introduce a delay of 1 second between requests\n",
    "                            time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
